import streamlit as st
import os
import base64
from datetime import datetime
from google.generativeai import GenerativeModel
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.utils import embedding_functions
from dotenv import load_dotenv
import os

load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

st.set_page_config(page_title="Auditoria de ReuniÃµes - Jettax", layout="wide")
st.title("ğŸ“Š Auditoria Inteligente de ReuniÃµes - Jettax")

# Inicializa modelos
embedding_model = SentenceTransformer("all-MiniLM-L6-v2")
ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-v2")
client = chromadb.Client()
collection = client.get_or_create_collection(name="reunioes_auditadas", embedding_function=ef)
model = GenerativeModel("gemini-1.5-pro")

st.sidebar.markdown("### âš™ï¸ OpÃ§Ãµes")
opcao = st.sidebar.radio("Selecione:", ["ğŸ” Nova ReuniÃ£o", "â“ Perguntar sobre ReuniÃ£o"])

# PÃ¡gina de upload e geraÃ§Ã£o de relatÃ³rio
if opcao == "ğŸ” Nova ReuniÃ£o":
    uploaded_file = st.file_uploader("ğŸ“¤ FaÃ§a o upload da transcriÃ§Ã£o (.txt)", type=["txt"])
    if uploaded_file:
        transcricao = uploaded_file.read().decode("utf-8")
        st.success("TranscriÃ§Ã£o carregada!")

        if st.button("ğŸš€ Gerar RelatÃ³rio"):
            prompt = f"""
VocÃª Ã© um auditor sÃªnior de Customer Success. Com base na transcriÃ§Ã£o completa abaixo, elabore um relatÃ³rio executivo com os seguintes tÃ³picos:

1. Sentimento geral do cliente
2. Postura e clareza do analista
3. Alinhamento entre discurso comercial e entrega
4. Sinais de risco de churn
5. Oportunidades comerciais ou operacionais
6. RecomendaÃ§Ãµes prÃ¡ticas para o time de CS ou lideranÃ§a

TranscriÃ§Ã£o:
{transcricao}
"""
            with st.spinner("Analisando com Gemini..."):
                resposta = model.generate_content(prompt).text

            nome_base = f"relatorio_jettax_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            html_path = f"{nome_base}.html"
           
            with open(html_path, "w", encoding="utf-8") as f:
                f.write("<html><body><pre style='font-family:Poppins,sans-serif'>" + resposta + "</pre></body></html>")

            st.success("âœ… RelatÃ³rio gerado com sucesso!")

            with open(html_path, "rb") as f:
                b64 = base64.b64encode(f.read()).decode()
                href = f'<a href="data:text/html;base64,{b64}" download="{html_path}">ğŸ“¥ Baixar RelatÃ³rio HTML</a>'
                st.markdown(href, unsafe_allow_html=True)

            # IndexaÃ§Ã£o para Q&A
            blocos = [p.strip() for p in transcricao.split("\n\n") if len(p.strip()) > 20]
            for idx, trecho in enumerate(blocos):
                collection.add(
                    documents=[trecho],
                    metadatas=[{"origem": html_path}],
                    ids=[f"{html_path}_{idx}"]
                )
            st.info("Embeddings gerados para Q&A!")

# PÃ¡gina de perguntas
if opcao == "â“ Perguntar sobre ReuniÃ£o":
    pergunta = st.text_input("Digite sua pergunta sobre a reuniÃ£o:")
    if pergunta:
        with st.spinner("Consultando..."):
            total_docs = len(collection.get()["documents"])
            resultados = collection.query(query_texts=[pergunta], n_results=min(3, total_docs))
            trechos = "\n\n".join([f"{i+1}. {doc}" for i, doc in enumerate(resultados["documents"][0])])
            prompt_qa = f"""
VocÃª Ã© um analista experiente de Customer Success. Baseando-se apenas nos trechos abaixo da reuniÃ£o, responda com precisÃ£o:

**Pergunta:** {pergunta}

**Trechos relevantes:**
{trechos}

**Resposta:** 
"""
            resposta = model.generate_content(prompt_qa).text
            st.markdown("### ğŸ’¡ Resposta:")
            st.write(resposta)
